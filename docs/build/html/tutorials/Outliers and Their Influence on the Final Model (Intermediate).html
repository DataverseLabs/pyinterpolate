
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Outliers and Their Influence on the Final Model - tutorial &#8212; Pyinterpolate 0.2.3 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Poisson Kriging - centroid based approach - tutorial" href="Poisson%20Kriging%20-%20Centroid%20Based%20%28Advanced%29.html" />
    <link rel="prev" title="Semivariogram regularization - tutorial" href="Semivariogram%20Regularization%20%28Intermediate%29.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Outliers-and-Their-Influence-on-the-Final-Model---tutorial">
<h1>Outliers and Their Influence on the Final Model - tutorial<a class="headerlink" href="#Outliers-and-Their-Influence-on-the-Final-Model---tutorial" title="Permalink to this headline">¶</a></h1>
<section id="Table-of-Contents:">
<h2>Table of Contents:<a class="headerlink" href="#Table-of-Contents:" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Read point data and take 10% of it as a sample for the further analysis (dataset A),</p></li>
<li><p>Check if outliers are present in a data and create additional dataset without outliers (dataset B),</p></li>
<li><p>Create the Variogram Point Cloud model for the datasets A and B,</p></li>
<li><p>Remove outliers from the datasets A and B,</p></li>
<li><p>Create four Ordinary Kriging models and compare their performance.</p></li>
</ol>
</section>
<section id="Level:-Intermediate">
<h2>Level: Intermediate<a class="headerlink" href="#Level:-Intermediate" title="Permalink to this headline">¶</a></h2>
</section>
<section id="Changelog">
<h2>Changelog<a class="headerlink" href="#Changelog" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 40%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Date</p></th>
<th class="head"><p>Change description</p></th>
<th class="head"><p>Author</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>2021-08-22</p></td>
<td><p>Initial release</p></td>
<td><p>&#64;szymon-datalions</p></td>
</tr>
</tbody>
</table>
</section>
<section id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this headline">¶</a></h2>
<p>Outliers may affect our analysis and the final interpolation results. In this tutorial we learn about their influence on the final model and we compare interpolation error for different scenarios where data is treated in a different ways.</p>
<p>We are able to remove too high or too low values at the preprocessing stage (check part 2 of the tutorial) or we can remove outliers directly from the variogram point cloud (part 4). Results from each type of preprocessing (and a raw dataset analysis) are different and we are going to compare them.</p>
<p>We use:</p>
<ul class="simple">
<li><p>DEM data which is stored in a file <code class="docutils literal notranslate"><span class="pre">sample_data/point_data/poland_dem_gorzow_wielkopolski</span></code>.</p></li>
</ul>
</section>
<section id="Import-packages">
<h2>Import packages<a class="headerlink" href="#Import-packages" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">pyinterpolate.distance</span> <span class="kn">import</span> <span class="n">calc_point_to_point_distance</span>
<span class="kn">from</span> <span class="nn">pyinterpolate.io_ops</span> <span class="kn">import</span> <span class="n">read_point_data</span>
<span class="kn">from</span> <span class="nn">pyinterpolate.kriging</span> <span class="kn">import</span> <span class="n">Krige</span>
<span class="kn">from</span> <span class="nn">pyinterpolate.semivariance</span> <span class="kn">import</span> <span class="n">build_variogram_point_cloud</span><span class="p">,</span> <span class="n">show_variogram_cloud</span><span class="p">,</span> <span class="n">remove_outliers</span>
<span class="kn">from</span> <span class="nn">pyinterpolate.semivariance</span> <span class="kn">import</span> <span class="n">calc_semivariance_from_pt_cloud</span>
<span class="kn">from</span> <span class="nn">pyinterpolate.semivariance</span> <span class="kn">import</span> <span class="n">TheoreticalSemivariogram</span>
</pre></div>
</div>
</div>
</section>
<section id="1)-Read-point-data-and-divide-it-into-training-and-test-set">
<h2>1) Read point data and divide it into training and test set<a class="headerlink" href="#1)-Read-point-data-and-divide-it-into-training-and-test-set" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Read data from file</span>

<span class="n">dem</span> <span class="o">=</span> <span class="n">read_point_data</span><span class="p">(</span><span class="s1">&#39;../sample_data/point_data/poland_dem_gorzow_wielkopolski&#39;</span><span class="p">,</span> <span class="n">data_type</span><span class="o">=</span><span class="s1">&#39;txt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Divide data into training and test set</span>

<span class="k">def</span> <span class="nf">create_train_test</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">training_fraction</span><span class="p">):</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="n">number_of_training_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">training_fraction</span><span class="p">)</span>
    <span class="n">training_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">idxs</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">number_of_training_samples</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">test_idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idxs</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">training_idxs</span><span class="p">]</span>
    <span class="n">training_set</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">training_idxs</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">test_set</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">test_idxs</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">return</span> <span class="n">training_set</span><span class="p">,</span> <span class="n">test_set</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">create_train_test</span><span class="p">(</span><span class="n">dem</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[15.32961159, 52.69870089, 26.50076103],
       [15.33317125, 52.69062817, 21.09065437],
       [15.14925544, 52.78377491, 52.66115952],
       ...,
       [15.22756798, 52.56374162, 58.7893219 ],
       [15.31735053, 52.75355397, 83.29890442],
       [15.29638809, 52.5900297 , 46.89881134]])
</pre></div></div>
</div>
</section>
<section id="2)-Check-outliers:-analyze-distribution-of-the-values">
<h2>2) Check outliers: analyze distribution of the values<a class="headerlink" href="#2)-Check-outliers:-analyze-distribution-of-the-values" title="Permalink to this headline">¶</a></h2>
<p>To find if our dataset contains outliers we are going to inspect all values in the <code class="docutils literal notranslate"><span class="pre">train</span></code> set. At the beginning we plot data distribution with the <code class="docutils literal notranslate"><span class="pre">violinplot</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Distribution plot</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">train</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_9_0.png" src="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_9_0.png" />
</div>
</div>
<blockquote>
<div><p><strong>NOTE:</strong> Your plot may be different than presented in the tutorial. Why is that? Because we take a random sample of 10% of values and after each iteration the algorithm takes different points for the analysis.</p>
</div></blockquote>
<p><strong>Clarification:</strong></p>
<p>Investigation of the plot tells us that our data is:</p>
<ul class="simple">
<li><p>grouped around the lowest values, and most of the values are below 50 meters,</p></li>
<li><p>has (probably) three different distributions mixed together, it can be a sign that Digital Elevation Model covers three different types of the elevation. One is grouped around 20 meters, next around 50 meters and the faintest is visible around 70 meters.</p></li>
</ul>
<p><strong>Violinplot</strong> is good for the distribution analysis. Especially if we are looking for the complex patterns in the dataset. But reading outliers from it may be challenging and we should change a plot type to understand if outliers exist in a dataset. The good choice is the <code class="docutils literal notranslate"><span class="pre">boxplot</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Boxplot</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">train</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_11_0.png" src="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_11_0.png" />
</div>
</div>
<p><strong>Boxplot</strong> is a special and very useful tool for the data visualization and analysis. Let’s analyze this plot from the bottom up to the top.</p>
<blockquote>
<div><p><strong>NOTE:</strong> Boxplot represents values sorted in the ascending order and their statistical properties: quartiles, median and outliers.</p>
</div></blockquote>
<ul class="simple">
<li><p>The bottom whisker (horizontal line) represents the lower range of values in our dataset,</p></li>
<li><p>The box lower line is the first quartile of a data or, in other words, 25% of values of our dataset are below this point. We name it Q1.</p></li>
<li><p>The middle line is a median of our dataset. We name it Q2 or median.</p></li>
<li><p>The upper line is the third quartile of a data or, in other words, 75% of values are below this point,</p></li>
<li><p>The top whisker represents the upper range of values in our dataset. We name it Q3.</p></li>
<li><p>Individual points (if they are exist then we see them as a points below the bottom whisker or above the top whisker) are considered as outliers. They could be outliers in the upper range as well as lower range of our data. Long distance between Q1 and the bottom whisker and/or between Q3 and the top whisker is an indicator of potential outliers. Package <strong>matplotlib</strong> calculates potential outliers based on the absolute distance from the Q1 or Q3 to the whiskers. Points below or above this
distance are treated as outliers. The outlier distance is calculated as the <span class="math notranslate nohighlight">\(weight * (Q3 - Q1)\)</span> where we can set <code class="docutils literal notranslate"><span class="pre">weight</span></code> but other parameters are read directly from the data.</p></li>
</ul>
<p>We use this knowledge to remove outliers from the dataset with the assumption that <em>outliers are rather anomalies than unbiased readings</em>. We will perform the outlier removal from the data with a more <em>aggresive</em> assumption than it is done in <strong>matplotlib</strong> and we set weight to the <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Create training set without outliers</span>

<span class="n">q1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">train</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.25</span><span class="p">)</span>
<span class="n">q3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">train</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.75</span><span class="p">)</span>

<span class="n">top_limit</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">+</span> <span class="p">(</span><span class="n">q3</span> <span class="o">-</span> <span class="n">q1</span><span class="p">)</span>

<span class="n">train_without_outliers</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">top_limit</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Length of the full training set is </span><span class="si">{}</span><span class="s1"> records&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Length of the pre-processed training set is </span><span class="si">{}</span><span class="s1"> records&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_without_outliers</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Length of the full training set is 689 records
Length of the pre-processed training set is 683 records
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">train_without_outliers</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribution of the training set without outliers&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">train_without_outliers</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Statistics of the training set without outliers&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_15_0.png" src="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_15_0.png" />
</div>
</div>
<p><strong>Clarification</strong>: with our data processing we have cut some records from the baseline training dataset. Distribution plot (<code class="docutils literal notranslate"><span class="pre">violinplot</span></code>) has shorter tail and ends more abruptly; and a <code class="docutils literal notranslate"><span class="pre">boxplot</span></code> of the new data doesn’t have any outliers. The one important thing to notice is that the observations are still skewed but this is not a problem for this concrete tutorial.</p>
<blockquote>
<div><p><strong>NOTE</strong>: if you are eager to know how to deal with the skewed datasets we recommend article <a class="reference external" href="https://anatomisebiostats.com/biostatistics-blog/transforming-skewed-data/">Transforming Skewed Data</a>.</p>
</div></blockquote>
</section>
<section id="3)-Create-the-Variogram-Point-Cloud-model-for-datasets-A-and-B">
<h2>3) Create the Variogram Point Cloud model for datasets A and B<a class="headerlink" href="#3)-Create-the-Variogram-Point-Cloud-model-for-datasets-A-and-B" title="Permalink to this headline">¶</a></h2>
<p>Now we are making one step further and we will transform both datasets with- and without- outliers and calculate variogram point clouds from these. Then we compare both variogram point clouds.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">get_variogram_point_cloud</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="n">number_of_lags</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="n">calc_point_to_point_distance</span><span class="p">(</span><span class="n">dem</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="n">max_range</span> <span class="o">/</span> <span class="n">number_of_lags</span>
    <span class="n">cloud</span> <span class="o">=</span> <span class="n">build_variogram_point_cloud</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">max_range</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cloud</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">full_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">calc_point_to_point_distance</span><span class="p">(</span><span class="n">train</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">cloud_full</span> <span class="o">=</span> <span class="n">get_variogram_point_cloud</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">full_distance</span><span class="p">)</span>
<span class="n">cloud_processed</span> <span class="o">=</span> <span class="n">get_variogram_point_cloud</span><span class="p">(</span><span class="n">train_without_outliers</span><span class="p">,</span> <span class="n">full_distance</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Show variogram cloud: initial training dataset</span>

<span class="n">show_variogram_cloud</span><span class="p">(</span><span class="n">cloud_full</span><span class="p">,</span> <span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;boxplot&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_20_0.png" src="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_20_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Show variogram cloud: pre-processed training dataset</span>

<span class="n">show_variogram_cloud</span><span class="p">(</span><span class="n">cloud_processed</span><span class="p">,</span> <span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;boxplot&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_21_0.png" src="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_21_0.png" />
</div>
</div>
<p><strong>Clarification:</strong> a quick look into the results shows that each lag is full of outliers in the top part of the semivariances values. Processed dataset has lowest absolute semivariance than the raw readings. Both variograms have a similar shape. Dispersion of semivariances seems to be very high in both cases. It is especially alarming when we consider the shortest distances where abrupt changes in the elevation are not so likely.</p>
<p>In the next cell we will check a standard deviation of the lag variances.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cloud_full</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Lag </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>

    <span class="n">v_raw</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
    <span class="n">v_pro</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cloud_processed</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
    <span class="n">v_smape</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">v_raw</span> <span class="o">-</span> <span class="n">v_pro</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">v_raw</span> <span class="o">+</span> <span class="n">v_pro</span><span class="p">)))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Standard Deviation raw dataset:&#39;</span><span class="p">,</span> <span class="n">v_raw</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Standard Deviation processed dataset:&#39;</span><span class="p">,</span> <span class="n">v_pro</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Symmetric Mean Absolute Percentage Error of Variances: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">v_smape</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Lag 0.00
Standard Deviation raw dataset: 83
Standard Deviation processed dataset: 84
Symmetric Mean Absolute Percentage Error of Variances: 1.20

Lag 0.02
Standard Deviation raw dataset: 312
Standard Deviation processed dataset: 313
Symmetric Mean Absolute Percentage Error of Variances: 0.32

Lag 0.04
Standard Deviation raw dataset: 508
Standard Deviation processed dataset: 500
Symmetric Mean Absolute Percentage Error of Variances: 1.59

Lag 0.06
Standard Deviation raw dataset: 626
Standard Deviation processed dataset: 594
Symmetric Mean Absolute Percentage Error of Variances: 5.25

Lag 0.08
Standard Deviation raw dataset: 686
Standard Deviation processed dataset: 643
Symmetric Mean Absolute Percentage Error of Variances: 6.47

Lag 0.10
Standard Deviation raw dataset: 686
Standard Deviation processed dataset: 641
Symmetric Mean Absolute Percentage Error of Variances: 6.78

Lag 0.12
Standard Deviation raw dataset: 666
Standard Deviation processed dataset: 619
Symmetric Mean Absolute Percentage Error of Variances: 7.32

Lag 0.14
Standard Deviation raw dataset: 637
Standard Deviation processed dataset: 588
Symmetric Mean Absolute Percentage Error of Variances: 8.00

Lag 0.16
Standard Deviation raw dataset: 617
Standard Deviation processed dataset: 573
Symmetric Mean Absolute Percentage Error of Variances: 7.39

Lag 0.18
Standard Deviation raw dataset: 611
Standard Deviation processed dataset: 575
Symmetric Mean Absolute Percentage Error of Variances: 6.07

Lag 0.20
Standard Deviation raw dataset: 622
Standard Deviation processed dataset: 584
Symmetric Mean Absolute Percentage Error of Variances: 6.30

Lag 0.22
Standard Deviation raw dataset: 645
Standard Deviation processed dataset: 599
Symmetric Mean Absolute Percentage Error of Variances: 7.40

Lag 0.24
Standard Deviation raw dataset: 633
Standard Deviation processed dataset: 590
Symmetric Mean Absolute Percentage Error of Variances: 7.03

Lag 0.26
Standard Deviation raw dataset: 556
Standard Deviation processed dataset: 537
Symmetric Mean Absolute Percentage Error of Variances: 3.48

Lag 0.28
Standard Deviation raw dataset: 486
Standard Deviation processed dataset: 470
Symmetric Mean Absolute Percentage Error of Variances: 3.35

Lag 0.30
Standard Deviation raw dataset: 355
Standard Deviation processed dataset: 345
Symmetric Mean Absolute Percentage Error of Variances: 2.86

</pre></div></div>
</div>
<p><strong>Clarification:</strong> The differences (sMAPE) per lag vary a lot. We can see that the preprocessing of raw values introduces the information lost. It is especially painful for the closest neighbors. It doesn’t mean that the preprocessing of raw observations is not recommended but it is a good idea to include the <strong>spatial component</strong> in the outliers detection process.</p>
<p>Not everything is wrong. Data cleaning has lowered the semivariances dispersion for the middle lags (where we have the largest number of point pairs for the analysis).</p>
<p>At this point we are not able to judge which dataset is better for the modeling. Instead we are going to remove outliers from the both <strong>variograms</strong> (instead of the <strong>raw data</strong>).</p>
</section>
<section id="4)-Remove-outliers-from-the-variograms">
<h2>4) Remove outliers from the variograms<a class="headerlink" href="#4)-Remove-outliers-from-the-variograms" title="Permalink to this headline">¶</a></h2>
<p>In this step we are going to use <strong>pyinterpolate’s</strong> function <code class="docutils literal notranslate"><span class="pre">remove_outliers()</span></code> to build additional two variogram point clouds from the raw and processed datasets. We delete the top part outliers of the <strong>semivariance values</strong> rather than the raw readings.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">raw_without_outliers</span> <span class="o">=</span> <span class="n">remove_outliers</span><span class="p">(</span><span class="n">cloud_full</span><span class="p">,</span> <span class="n">exclude_part</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mf">1.25</span><span class="p">)</span>
<span class="n">prep_without_outliers</span> <span class="o">=</span> <span class="n">remove_outliers</span><span class="p">(</span><span class="n">cloud_processed</span><span class="p">,</span> <span class="n">exclude_part</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mf">1.25</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">data_raw</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cloud_full</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
<span class="n">data_raw_not_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">raw_without_outliers</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
<span class="n">data_prep</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cloud_processed</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
<span class="n">data_prep_not_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">prep_without_outliers</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data_raw</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Semi-variances Distribution in the Raw Dataset&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Lag number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Semivariance value&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data_raw_not_out</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Raw Dataset after the Outliers Detection and Removal&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Lag number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Semivariance value&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data_prep</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Semi-variances Distribution in the Pre-processed Dataset&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Lag number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Semivariance value&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data_prep_not_out</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Pre-processed Dataset after the Outliers Detection and Removal&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Lag number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Semivariance value&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_28_0.png" src="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_28_0.png" />
</div>
</div>
<p><strong>Clarification:</strong> Comparison of multiple variogram clouds could be hard. We see that the largest semivariances are present in the raw data. A heavily processed data has the lowest number of outliers. The medians in each dataset are distributed over a similar pattern. How is it similar? We can check it if we transform the variogram point cloud into the experimental semivariogram. Pyinterpolate has function for it: <code class="docutils literal notranslate"><span class="pre">calc_semivariance_from_pt_cloud()</span></code>. We use it and compare four plots of
semivariances to gain more insight into the transformations.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">raw_semivar</span> <span class="o">=</span> <span class="n">calc_semivariance_from_pt_cloud</span><span class="p">(</span><span class="n">cloud_full</span><span class="p">)</span>
<span class="n">raw_semivar_not_out</span> <span class="o">=</span> <span class="n">calc_semivariance_from_pt_cloud</span><span class="p">(</span><span class="n">raw_without_outliers</span><span class="p">)</span>
<span class="n">prep_semivar</span> <span class="o">=</span> <span class="n">calc_semivariance_from_pt_cloud</span><span class="p">(</span><span class="n">cloud_processed</span><span class="p">)</span>
<span class="n">prep_semivar_not_out</span> <span class="o">=</span> <span class="n">calc_semivariance_from_pt_cloud</span><span class="p">(</span><span class="n">prep_without_outliers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">raw_semivar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">raw_semivar_not_out</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">prep_semivar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">prep_semivar_not_out</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Comparison of experimental semivariograms created with the different data preprocessing techniques&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Semivariance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Lag number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Raw&#39;</span><span class="p">,</span> <span class="s1">&#39;Raw - remove_outliers()&#39;</span><span class="p">,</span> <span class="s1">&#39;Pre-processed&#39;</span><span class="p">,</span> <span class="s1">&#39;Pre-processed - remove_outliers()&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_31_0.png" src="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_31_0.png" />
</div>
</div>
<p><strong>Clarification:</strong> An understanding of those plots is not an easy task. Let’s divide reasoning into multiple points:</p>
<ul class="simple">
<li><p>Raw dataset and preprocessed raw dataset show a similar pattern, the differences are more pronounced for the distant lags than for the closest point pairs,</p></li>
<li><p>Datasets with the cleaned variograms are different from the raw data. The absolute semivariance values per lag are smaller and the semivariogram pattern is slightly different. What is interesting is that the possible two distributions within the dataset are more visible in the case of cleaned variograms (one distribution with a peak around 6th lag and other with a peak around 13th lag).</p></li>
<li><p>The differences between semivariograms are mostly visible at larger distances. For the closest point pairs differences are smaller.</p></li>
</ul>
<p>Semivariograms visual inspection does not infor us of the modeling performance but we can assume that models will be slightly different. Let’s test this assumption!</p>
</section>
<section id="5)-Create-Four-Ordinary-Kriging-models-based-on-the-four-Variogram-Point-Clouds-and-compare-their-performance">
<h2>5) Create Four Ordinary Kriging models based on the four Variogram Point Clouds and compare their performance<a class="headerlink" href="#5)-Create-Four-Ordinary-Kriging-models-based-on-the-four-Variogram-Point-Clouds-and-compare-their-performance" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">number_of_ranges</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># Fit different semivariogram models into prepared datasets and variograms</span>

<span class="c1"># Raw</span>
<span class="n">raw_theo</span> <span class="o">=</span> <span class="n">TheoreticalSemivariogram</span><span class="p">(</span><span class="n">points_array</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                                    <span class="n">empirical_semivariance</span><span class="o">=</span><span class="n">raw_semivar</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">raw_theo</span><span class="o">.</span><span class="n">find_optimal_model</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">number_of_ranges</span><span class="o">=</span><span class="n">number_of_ranges</span><span class="p">)</span>

<span class="c1"># Raw with cleaned variogram</span>
<span class="n">raw_theo_no_out</span> <span class="o">=</span> <span class="n">TheoreticalSemivariogram</span><span class="p">(</span><span class="n">points_array</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                                           <span class="n">empirical_semivariance</span><span class="o">=</span><span class="n">raw_semivar_not_out</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">raw_theo_no_out</span><span class="o">.</span><span class="n">find_optimal_model</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">number_of_ranges</span><span class="o">=</span><span class="n">number_of_ranges</span><span class="p">)</span>

<span class="c1"># Preprocessed</span>
<span class="n">prep_theo</span> <span class="o">=</span> <span class="n">TheoreticalSemivariogram</span><span class="p">(</span><span class="n">points_array</span><span class="o">=</span><span class="n">train_without_outliers</span><span class="p">,</span>
                                     <span class="n">empirical_semivariance</span><span class="o">=</span><span class="n">prep_semivar</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">prep_theo</span><span class="o">.</span><span class="n">find_optimal_model</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">number_of_ranges</span><span class="o">=</span><span class="n">number_of_ranges</span><span class="p">)</span>

<span class="c1"># Preprocessed with cleaned variogram</span>
<span class="n">prep_theo_no_out</span> <span class="o">=</span> <span class="n">TheoreticalSemivariogram</span><span class="p">(</span><span class="n">points_array</span><span class="o">=</span><span class="n">train_without_outliers</span><span class="p">,</span>
                                            <span class="n">empirical_semivariance</span><span class="o">=</span><span class="n">prep_semivar_not_out</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">prep_theo_no_out</span><span class="o">.</span><span class="n">find_optimal_model</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">number_of_ranges</span><span class="o">=</span><span class="n">number_of_ranges</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Set Kriging models</span>

<span class="c1"># Raw</span>
<span class="n">raw_model</span> <span class="o">=</span> <span class="n">Krige</span><span class="p">(</span><span class="n">semivariogram_model</span><span class="o">=</span><span class="n">raw_theo</span><span class="p">,</span> <span class="n">known_points</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>

<span class="c1"># Raw &amp; cleaned</span>
<span class="n">c_raw_model</span> <span class="o">=</span> <span class="n">Krige</span><span class="p">(</span><span class="n">semivariogram_model</span><span class="o">=</span><span class="n">raw_theo_no_out</span><span class="p">,</span> <span class="n">known_points</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>

<span class="c1"># Preprocessed</span>
<span class="n">prep_model</span> <span class="o">=</span> <span class="n">Krige</span><span class="p">(</span><span class="n">semivariogram_model</span><span class="o">=</span><span class="n">prep_theo</span><span class="p">,</span> <span class="n">known_points</span><span class="o">=</span><span class="n">train_without_outliers</span><span class="p">)</span>

<span class="c1"># Preprocessed &amp; cleaned</span>
<span class="n">c_prep_model</span> <span class="o">=</span> <span class="n">Krige</span><span class="p">(</span><span class="n">semivariogram_model</span><span class="o">=</span><span class="n">prep_theo_no_out</span><span class="p">,</span> <span class="n">known_points</span><span class="o">=</span><span class="n">train_without_outliers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Build test function</span>

<span class="k">def</span> <span class="nf">test_kriging_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="n">nn</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function tests performance of a given kriging model.</span>

<span class="sd">    INPUT:</span>

<span class="sd">    :param model: (Krige) Kriging model,</span>
<span class="sd">    :param test_set: (array),</span>
<span class="sd">    :param nn: (int) default=16, number of neighbors.</span>

<span class="sd">    OUTPUT:</span>

<span class="sd">    :returns: (list) root mean squared errors of prediction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rmses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">test_set</span><span class="p">:</span>
        <span class="n">coordinates</span> <span class="o">=</span> <span class="n">pt</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">pt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">ordinary_kriging</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">nn</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">value</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">rmses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rmses</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">r_test</span> <span class="o">=</span> <span class="n">test_kriging_model</span><span class="p">(</span><span class="n">raw_model</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cr_test</span> <span class="o">=</span> <span class="n">test_kriging_model</span><span class="p">(</span><span class="n">c_raw_model</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">p_test</span> <span class="o">=</span> <span class="n">test_kriging_model</span><span class="p">(</span><span class="n">prep_model</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cp_test</span> <span class="o">=</span> <span class="n">test_kriging_model</span><span class="p">(</span><span class="n">c_prep_model</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">r_test</span><span class="p">,</span> <span class="n">cr_test</span><span class="p">,</span> <span class="n">p_test</span><span class="p">,</span> <span class="n">cp_test</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span>
                  <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Raw&#39;</span><span class="p">,</span> <span class="s1">&#39;Raw-cleaned&#39;</span><span class="p">,</span> <span class="s1">&#39;Preprocessed&#39;</span><span class="p">,</span> <span class="s1">&#39;Preprocessed-cleaned&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s1">&#39;Raw&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;Raw-cleaned&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;Preprocessed&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;Preprocessed-cleaned&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_42_0.png" src="../_images/tutorials_Outliers_and_Their_Influence_on_the_Final_Model_(Intermediate)_42_0.png" />
</div>
</div>
<p>It is very hard to distinguish any differences in the figure but we can use <code class="docutils literal notranslate"><span class="pre">.describe()</span></code> method of <strong>pandas</strong> to get the columns statistic:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Raw</th>
      <th>Raw-cleaned</th>
      <th>Preprocessed</th>
      <th>Preprocessed-cleaned</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6206.000000</td>
      <td>6206.000000</td>
      <td>6206.000000</td>
      <td>6206.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.936283</td>
      <td>2.936742</td>
      <td>2.956846</td>
      <td>2.957840</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.686328</td>
      <td>3.685557</td>
      <td>3.707982</td>
      <td>3.708420</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000491</td>
      <td>0.000152</td>
      <td>0.000491</td>
      <td>0.000152</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.617843</td>
      <td>0.614906</td>
      <td>0.614773</td>
      <td>0.612816</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.607936</td>
      <td>1.602791</td>
      <td>1.617333</td>
      <td>1.616114</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.812796</td>
      <td>3.813395</td>
      <td>3.839099</td>
      <td>3.854755</td>
    </tr>
    <tr>
      <th>max</th>
      <td>36.599110</td>
      <td>36.602001</td>
      <td>36.599110</td>
      <td>36.602001</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p><strong>Clarification:</strong> In this particular case the final statistics goes hand in hand with the initial assumptions that:</p>
<p><strong>a)</strong> Raw dataset has lowest error of prediction. The rationale behind it is that if we throw away the observations at the preprocessing step we risk an information lost. It could damage our model.</p>
<p><strong>b)</strong> Raw dataset with the <strong>cleaned variogram</strong> is the best one. We have removed the point pairs with the largest error. In reality we got rid off the potentially wrong measurements where at one point elevation is small and it’s neighbour is very high.</p>
<blockquote>
<div><p><strong>NOTE:</strong> Example in this tutorial is related to the Digital Elevation Model which was preprocessed by the data provider (<em>Copernicus Land Monitoring Services</em>). You shouldn’t get impression that the raw data preprocessing and filtering is not required for the analysis. There are cases where the sensor may produce unreliable and biased results, as example a saturated pixel from the satellite camera. It is better to remove it with the specific noise-filtering algorithm before the variogram
point cloud development.</p>
</div></blockquote>
<hr class="docutils" />
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Pyinterpolate</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup.html">Setup</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code_documentation.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms.html">Algorithms Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribution.html">Contribution to Pyinterpolate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../tutorials.html">Tutorials</a><ul>
      <li>Previous: <a href="Semivariogram%20Regularization%20%28Intermediate%29.html" title="previous chapter">Semivariogram regularization - tutorial</a></li>
      <li>Next: <a href="Poisson%20Kriging%20-%20Centroid%20Based%20%28Advanced%29.html" title="next chapter">Poisson Kriging - centroid based approach - tutorial</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Szymon Moliński.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/tutorials/Outliers and Their Influence on the Final Model (Intermediate).ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>